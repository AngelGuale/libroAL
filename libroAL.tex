\documentclass[10pt,a4paper]{report}
\usepackage[spanish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{makeidx}

\RequirePackage{algebraLineal}


\newtheorem{theorem}{Teorema}[chapter]
\newtheorem{lemma}[theorem]{Lema}


\theoremstyle{definition}
\newtheorem{dfn}{Definición}[chapter]
\newtheorem{ejemplo}{Ejemplo}[chapter]
\newtheorem{ejercicio}{Ejercicio}[chapter]


\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\numberwithin{section}{chapter}
\numberwithin{equation}{chapter}

\newcounter{tacounter}
\newenvironment{trabajoautonomo}[0]
    {\begin{center}
    \refstepcounter{tacounter}
     \textbf{Trabajo autónomo \thetacounter}\\[1ex]
    \begin{tabular}{|p{0.9\textwidth}|}
    \hline\\
    }
    { 
    \\\\\hline
    \end{tabular} 
    \end{center}
    }
\numberwithin{tacounter}{chapter}

\newenvironment{obsimp}[0]
    {\noindent$\star$ \textbf{Observación importante}:
  \itshape
    }
    { 
    \\
    }


%    For a single index; for multiple indexes, see the manual
%    "Instructions for preparation of papers and monographs:
%    AMS-LaTeX" (instr-l.pdf in the AMS-LaTeX distribution).

\author{Jorge Vielma, Angel Guale}
\title{Álgebra Lineal}

\makeindex

\begin{document}
\maketitle
%    Dedication.  If the dedication is longer than a line or two,
%    remove the centering instructions and the line break.
%\cleardoublepage
%\thispagestyle{empty}
%\vspace*{13.5pc}
%\begin{center}
%  Dedication text (use \\[2pt] for line break if necessary)
%\end{center}
%\cleardoublepage
%    Change page number to 7 if a dedication is present.
\setcounter{page}{4}
\tableofcontents

\printindex
\chapter{Espacios Vectoriales Reales}
\section{Espacios Vectoriales reales}

\begin{dfn}[Espacio vectorial real]
Un espacio vectorial real es una cuarteta $(V, \dobler, +, \odot)$ donde V es un conjunto no vacío , $\dobler$ es el campo de los números reales, + es una operación en V llamada suma o adición y $\odot$ es una operación en V llamada multiplicación por un escalar. Los escalares son los elementos de $\dobler$ y que cumplen con los diferentes axiomas. \index{Espacio Vectorial}


\end{dfn}
\subsubsection*{Axiomas para la suma}
\begin{enumerate}
\item Si $u$ y $v$ son elementos de $V$, $u+v$ es un elemento de V.
\item Si $u$, $v$, y $w$ son elementos de $V$, entonces $u+v=v+u$. Es decir, la suma es una operación conmutativa.
\item Si $u$, $v$, y $w$ son elementos de $V$, entonces  $(u+v)+w=u+(v+w)$. Es decir, la operación es asociativa.
\item Existe un elemento de $V$, llamado elemento nulo y denotado por $\mathbf{0}_v$, tal que para todo $u$ en $V$, $u + \mathbf{0}_v = \mathbf{0}_v +u = u$.
\item Para cada $u$ en $V$ existe un único elemento en $V$, llamado $-u$, tal que $u+(-u)=\mathbf{0}_v$.
\end{enumerate}

\subsubsection*{Axiomas para la multiplicación por escalares}
\begin{enumerate}
\item Si $\alpha$ es un número real y $u$ es un elemento de $V$, entonces $\alpha u$ es un elemento de $V$.
\item Si $\alpha$ es un número real y $u$ y $v$ son elementos de $V$, entonces $\alpha (u+v) = \alpha u + \alpha v$. Es decir la multiplicación por un escalar es distributiva con respecto a la suma de vectores.
\item Si $\alpha$ y $\beta$ son números reales y $u$ es un elemento de $V$, entonces $(\alpha + \beta)u = \alpha u + \beta u$. Es decir la multiplicación por un escalar es distributiva con respecto a la suma de escalares.
\item Si $\alpha$ y $\beta$ son números reales y $u$ es un elemento de $V$, entonces $(\alpha \beta)u = \beta(\alpha u)$.
\item Si $u$ es un elemento de $V$, entonces $1 \odot u = u$.

\end{enumerate}

\begin{trabajoautonomo}
Sea $(E, +, \odot)$ un espacio vectorial real. Pruebe que
\begin{enumerate}
\item El elemento neutro $\mathbf{0}_E$ es único.
\item Para cada $e$ en $E$, el elemento $-e$ es único.
\item Para cada $e$ en $E$, $\mathbf{0}_E \odot e = 0$.
\item Para cada $e$ en $E$, $(-1)e = -e$.
\item Para cada $\lambda$ en $\mathbb{R}$, $\lambda \odot \mathbf{0}_E = \mathbf{0}_E$.
\item Si $\alpha v = \mathbf{0}_E$, entonces $\alpha = 0$ o $v=\mathbf{0}_E$.

\end{enumerate}
\end{trabajoautonomo}
\begin{ejemplo}

El espacio \rdos \ con las operaciones $(x,y)+(w,z) = (x+w,y+z)$ y la multiplicación por un escalar $\lambda$, $\lambda (x,y) = (\lambda x,\lambda y)$.

\end{ejemplo}

\begin{ejemplo}
El espacio de todos los polinomios de grado menor o igual que $n$, para un número natural $n$ fijo, con la operación normal de suma de polinomios y la multiplicación usual de un polinomio por un número real.
\end{ejemplo}

\begin{ejemplo}
El espacio de todas las matrices $n \times m$ con la operación usual de suma de matrices y multiplicación de una matriz por un número real.(Aquí $n$ y $m$ son números naturales fijos y distintos de cero).


\end{ejemplo}

\section{Subespacios Vectoriales}
\begin{dfn}
Sea $(E, +, \odot)$ un espacio vectorial real y $S$ un subconjunto no vacío de $E$. Entonces se dice que $S$ es un subespacio vectorial de $E$, si con las operaciones heredadas de $E$, $(S, +, \odot)$ es también un espacio vectorial.

\end{dfn}

\begin{ejemplo}
Sea $E = \rtres$ y $S = \llaves{(x, y, z) \in \rtres}{5x + 2y + z = 0}$ entonces $S$ es un subespacio de \rtres.
\end{ejemplo}

\begin{ejemplo}
Sea $E$ el espacio \mdosxdos \ de todas las matrices cuadradas $2 \times 2$ con las operaciones usuales de suma de matrices y de multiplicación por un escalar y $S$ el conjunto de las matrices diagonales, es decir las matrices de la forma \matrdxd{a & 0}{0 & b}, entonces $S$ es un subespacio de $E$.

\end{ejemplo}

\begin{ejemplo}
Sea $E$ el espacio \ptres \ de todos los polinomios de grado menor o igual a 3, con la suma y multiplicación por un escalar usuales. Sea $S$ el conjunto de los polinomios \pdos \ de grado menor o igual a 2, entonces $S$ es un subespacio de $E$.
\end{ejemplo}

\begin{ejemplo}

Sea $E$ un espacio vectorial real, $V$ y $W$ dos subespacios vectoriales de $E$, entonces $V + W =\llaves{a+b}{a \in V \, , \, b \in W}$ y $V \cap W = \llaves{a}{a \in V \cap W}$ son también subespacios vectoriales reales.
\end{ejemplo}

\section{Combinaciones lineales y subespacios generados}
\begin{dfn}
Sea $(E, +, \odot)$ un espacio vectorial real y sean $B=\conjvect{v}{n}$ un subconjunto de vectores en $E$. Un vector $v$ en $E$ se dice que es una combinación lineal de los vectores en $B$ si existen escalares $\alpha_1$, $\alpha_2$, $\ldots$ , $\alpha_n$ en \dobler , tales que $v=\av{\alpha_1}{v_1} + \av{\alpha_2}{v_2} + \ldots + \av{\alpha_n}{v_n}$.

\end{dfn}

\begin{ejemplo}
Cualquier vector $(a, b, c)$ en \rtres puede ser expresado como una combinación lineal de los vectores  $(1,0,0)$,$(0,1,0)$ y $(0,0,1)$.

\end{ejemplo}

\begin{ejemplo}
El vector $(4,5,5)$ puede ser expresado como una combinación lineal de los vectores $(1,2,3)$, $(-1,1,4)$ y $(3,3,2)$.
\end{ejemplo}

\begin{theorem}
Sea $(E, +, \odot)$ un espacio vectorial y $A$ un subconjunto finito de $E$. El conjunto de todas las combinaciones lineales de elementos de $A$ es un subespacio de $E$ y se llama subespacio generado por $A$ y se denota por $CL(A)$.
\end{theorem}

\begin{proof}

$\mathbf{0}_v \in CL(A)$ por el comentario anterior.\\
Sean $u$, $v$ en $CL(A)$, entonces
\begin{align*}
u &=\av{\alpha_1}{v_1} + \ldots + \av{\alpha_n}{v_n}\\ 
v&=\av{\beta_1}{v_1} + \ldots + \av{\beta_n}{v_n}
\end{align*}
entonces
\begin{align*}
u + v &= (\av{\alpha_1}{v_1} + \ldots + \av{\alpha_n}{v_n}) + (\av{\beta_1}{v_1} + \ldots + \av{\beta_n}{v_n})\\
u + v &=(\alpha_1 + \beta_1)\,v_1 + \ldots + (\alpha_n + \beta_n)\, v_n
\end{align*}
Así
$$u + v \in CL(A)$$
Sea $u \in CL(A)$ y $\alpha \in \dobler$
\begin{align*}
\alpha u &= \alpha(\av{\alpha_1}{v_1} + \ldots + \av{\alpha_n}{v_n})\\
\alpha u &= (\alpha \alpha_1)v_1 + \ldots + (\alpha \alpha_n)v_n
\end{align*}
luego $\alpha u \in CL(A)$\\

$\therefore$ $CL(A)$ es un subespacio vectorial de $V$. \qedhere \\ %%%%%%%  el \qedhere es el QED

\end{proof}
El subespacio $CL(A)$ es llamado espacio generado por \conjvect{v}{n}. Si $V = CL(A)$ entonces decimos que $A$ genera al espacio $V$ o que $A$ es conjunto generador de $V$.

\begin{ejemplo}
Veamos que $A = \llav{(1,2,0),(0,1,-1),(1,1,2)}$ genera a \rtres .\
En efecto veamos que cualquier vector $(x,y,z)$ es una combinación lineal de los elementos de $A$. Es decir debemos encontrara escalares $\alpha$, $\beta$ y $\lambda \in \dobler$ tales que $$(x_0, y_0, z_0) = \alpha (1,2,0) + \beta (0,1,-1) + \lambda (1,1,2)$$
lo que nos conduce al estudio del sistema 

$$\left\{
\begin{array}{rcl}
\alpha + \lambda &=& x_0\\
2 \alpha + \beta + \lambda &=& y_0\\
- \beta + 2\alpha &=& z_0 
\end{array}
\right.$$

Donde se obtiene que 
\begin{align*}
\alpha &= 3x_0 - y_0 -z_0\\
\beta &=-4 x_0 +2 y_0 +z_0\\
\lambda &= -2 x_0 + y_0 +z_0 
\end{align*}

\end{ejemplo}

\section{Conjuntos linealmente independientes}
El subconjunto $A= \conjvect{v}{n}$ de un espacio vectorial $V$ se dice que es linealmente independiente si la combinación lineal $\lambda_1 v_1 + \lambda v_2 + \ldots + \lambda v_n = 0$ tiene como única solución la trivial, es decir que $\lambda_1 = \lambda_2 = \ldots = \lambda_n = 0$. En caso contrario se dice que $A$ es linealmente dependiente.

\begin{ejemplo}

Determinar si el conjunto de vectores $A= \{(1,2,3),(-2,1,1),(8,6,10)\}$ es linealmente independiente o no.\\
Planteamos la igualdad 
$$\alpha (1,2,3) + \beta (-2,1,1) + \lambda (8,6,10) = (0,0,0)$$
de donde se obtiene que 
$$\left\{
\begin{array}{rcl}
\alpha - 2\beta +8 \lambda & = & 0\\
2 \alpha + \beta + 6\lambda & = & 0\\
3\alpha + \beta + 10 \lambda & = & 0
\end{array}
\right.$$
Al hacer el análisis del sistema obtenemos que existen infinitas soluciones. Así que el conjunto $A$ es linealmente dependiente.
\end{ejemplo}

\begin{ejemplo}
Veamos que el conjunto $A= \{(3,-2,2),(3,-1,4),(1,0,5)\}$ es linealmente independiente.\\
Consideremos $$\alpha (3,-2,2) + \beta (3,-1,4) + \lambda (1,0,5) = (0,0,0)$$
y obtenemos
$$\left\{
\begin{array}{rcl}
3 \alpha + 3 \beta + \lambda & = & 0\\
-2 \alpha - \beta & = &0\\
2 \alpha +4 \beta +5 \lambda & = & 0

\end{array}
\right.$$
Al reducir de forma escalonada la matriz
$$\left(
\begin{array}{rrr}
3 & 3 & 1\\
-2 & -1 & 0\\
2 & 4 & 5
\end{array}
\right)\\
\sim \\
\left(
\begin{array}{rrr}
1 & 0 & 0\\
0 & 1 &0\\
0 &0 &1
\end{array}
\right)\\$$
Entonces el sistema tiene solución y esta es la trivial $\alpha = \beta = \lambda = 0$.
\end{ejemplo}
Recordemos que las matrices reales $2 \times 2$ forman un espacio vectorial.

\begin{ejemplo}

Veamos que $H = \left\{ \matrdxd{-1 & 2}{0 & 1}, \matrdxd{2 & 1}{1 & 1} , \matrdxd{0 & 2}{-1 & 0} \right \}$ es linealmente independiente.\\
Consideremos la igualdad
$$\alpha \matrdxd {-1 & 2}{0&1} + \beta \matrdxd {2&1}{1&1} + \lambda \matrdxd {0 & 2}{-1 & 0} = \matrdxd {0&0}{0&0}$$
de donde se obtiene
$$\left\{
\begin{array}{rcl}
-\alpha + 2\beta &=&0\\
2\alpha +\beta 2\lambda &=&0\\
\beta - \lambda &=& 0\\
\alpha + \beta &=&0

\end{array}
\right.$$
y obtenemos que la única solución es $\alpha = \beta = \lambda = 0$.\\
\end{ejemplo}

\section{Base y dimensión de un espacio vectorial}
Sea $V$ un espacio vectorial real y $A= \conjvect{v}{n}$ un subconjunto finito de $V$. Diremos que $A$ es una base de $V$, si y solo si, $A$ es linealmente independiente y genera  a $V$.

\begin{ejemplo}
Determine si la matriz \matrdxd {-1 & 7}{8&-1} se puede escribir como combinación lineal de las matrices \matrdxd{1&0}{2&1} , \matrdxd {2&-3}{0&2} , \matrdxd {0&1}{2&0}. \\
Necesitamos averiguar si existen números reales $\alpha$, $\beta$, $\gamma$ tales que
$$\matrdxd {-1&7}{8&-1} = \alpha \matrdxd {1&0}{2&1} + \beta \matrdxd {2&-3}{0&2} + \gamma \matrdxd {0&1}{2&0}$$
lo cual conduce a resolver el siguiente sistema de ecuaciones
$$\left\{
\begin{array}{rcr}
\alpha + 2\beta &=&-1\\
-3\beta + \gamma &=&7\\
2\alpha + 2 \gamma &=& 8\\
\alpha +2\beta &=& -1

\end{array}
\right.$$

\end{ejemplo}

\begin{obsimp}
En cualquier espacio vectorial, el vector nulo $\mathbf{0}_v$ es combinación lineal de cualquier familia finita de elementos de $V$ \conjvect {v}{n} por $\mathbf{0}_v = 0 v_1 + 0 v_2 + \ldots + 0 v_n$.\\
\end{obsimp}

\begin{dfn}
Un subconjunto $S$ de un espacio vectorial $(V, +, \odot)$ se dice que es un subconjunto linealmente independiente maximal de $V$ si\\
\begin{enumerate}
\item $S$ es linealmente independiente.
\item Para cualquier $w \in V$ y $w \notin S$ el subconjunto $S'$ de $V$ formado por $S$ unido con $\{w\}$ es linealmente independiente.
\end{enumerate}
\end{dfn}

\begin{dfn}
Un subconjunto de $M$ de un espacio vectorial se dice que es un subconjunto generador minimal de $V$ si
\begin{enumerate}
\item $M$ genera a $V$.
\item Si a $M$ se le quita un elemento $v_0$ entonces $M \setminus \{w\}$ no es un conjunto generador.
\end{enumerate}
\end{dfn}
Si $V$ es un subespacio vectorial y $B = \conjvect{v}{n}$ es una base para $V$, entonces los coeficientes de la combinación lineal $\alpha_1 v_1 + \alpha_2 v_2 + \ldots + \alpha_n v_n = v$ se denominan las coordenadas de $v$ respecto a la base $B$ y será representado por 
$$(v)_B = \left( \begin{array}{c}
\alpha_1\\
\alpha_2\\
\vdots\\
\alpha_n  \end{array} \right)$$

\begin{obsimp}
Sea $V$ un espacio vectorial. Si una base está conformada por $n$ vectores, entonces todas las demás bases tendrán $n$ vectores.
\end{obsimp}

\begin{obsimp}
Sea $V$ un espacio vectorial. Si existe una base con $n$ vectores, diremos que $n$ es la dimensión de $V$ y será denotado como $dim (V) = n$.
\end{obsimp}

\begin{theorem}
Si el espacio vectorial $(V , + , \odot)$ tiene un subconjunto linealmente independiente maximal \conjvect{v}{n} entonces es una base para $V$.

\end{theorem}


\begin{theorem}
Si el espacio vectorial $(V , +, \odot)$ tiene un subconjunto minimal $B$, entonces $B$ es una base para $V$.
\end{theorem}


\chapter{Valores y Vectores Característicos}
\begin{dfn}
Sea $A$ una matriz $n\times n$. Un escalar $\lambda$ se dice que es un valor característico de $A$ si existe un vector no nulo $x$ en \rn \ tal que
$$A X = \lambda X$$
El vector $x$ se llama vector característico de $A$ correspondiente a $\lambda$.
\end{dfn}

\begin{ejemplo}
Sea $A = \left( \begin{array}{rrr}
1 & -2 & 1\\
0 & 0 & 0\\
0 & 1 & 1
\end{array} \right)$.\\
Compruebe que $x= (-3, -1, 1)$ es un vector característico de $A$.\\

\noindent En efecto 
\begin{align*}
\left( \begin{array}{rrr}
1 & -2 &1\\
0 & 0 & 0\\
0&1&1
\end{array} \right)
\vectrtres {-3}{-1}{1} &=
\left( \begin{array}{c}
-3+2+1\\
0\\
-1+1
\end{array} \right)\\
&= \vectrtres {0}{0}{0}\\
&= 0 \vectrtres {-3}{-1}{1}
\end{align*}
\end{ejemplo}

\begin{ejemplo}
Sea $A =\matrdxd {10 & -18}{6 & -11}$ y $v= \vectrdos{2}{1}$\\
\begin{align*}
\matrdxd{10 & -18}{6 & -11} \vectrdos{2}{1} &= \vectrdos {20-18}{12-11}\\
&= \vectrdos {2}{1}
\end{align*}
Así tenemos que 
$$\matrdxd{10 & -18}{6 & -11} \vectrdos {2}{1} = 1 \vectrdos {2}{1}$$
Lo cual indica que $\lambda = 1$ es un valor característico correspondiente al vector característico \vectrdos{2}{1}.
\begin{align*}
\matrdxd {10 & -18}{6 & -11} \vectrdos {3}{2} &= \vectrdos {30-36}{18-22}\\
&= \vectrdos {-6}{-4}\\
&= -2 \vectrdos {3}{2}
\end{align*}
De igual forma $\lambda = -2$ es el valor característico correspondiente al vector característico \vectrdos{3}{2}.
\end{ejemplo}

\begin{ejemplo}
Sea $A = \left( \begin{array}{rrr}
1 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 1
\end{array} \right)$ y $v = \vectrtres {a}{b}{c}$ un vector cualquiera
\begin{align*}
Av &= \left( \begin{array}{rrr}
1 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 1
\end{array} \right) \vectrtres{a}{b}{c}\\
&= \vectrtres{a}{b}{c}
\end{align*}
Entonces $\lambda = 1$ es un valor característico de cualquier vector $v$ y todo vector $v \neq 0$ es un vector característico de $A$.
\end{ejemplo}

\noindent Sea $\lambda$ un valor característico de $A$ correspondiente al vector característico $v \neq 0$. Entonces 
$$Av = \lambda v$$
Ahora como $\lambda v = \lambda I v$ donde $I$ es la matriz identidad, obtenemos que 
$$Av = \lambda I v$$
De donde se obtiene la igualdad 
$$(A - \lambda I) v = 0$$
\begin{align*}
\left[ \left( \begin{array}{cccc}
a_{11} & a_{12} & \ldots & a_{1n}\\
a_{21} & a_{22} & \ldots & a_{2n}\\
\vdots & \vdots & \ddots & \vdots\\
a_{n1} & a_{n2} & \ldots & a_{nn}
\end{array} \right) - \lambda \left( \begin{array}{cccc}
1 & 0 & \ldots & 0\\
0 & 1 & \ldots & 0\\
\vdots & \vdots & \ddots & \vdots\\
0 & 0 & \ldots & 1
\end{array} \right) \right] \left( \begin{array}{c}
x_1\\
x_2\\
\vdots\\
x_n
\end{array} \right) &= \left( \begin{array}{c}
0\\
0\\
\vdots\\
0
\end{array} \right)\\
\left( \begin{array}{cccc}
a_{11} - \lambda & a_{12} & \ldots & a_{1n}\\
a_{21} & a_{22} - \lambda & \ldots & a_{2n}\\
\vdots & \vdots & \ddots & \vdots\\
a_{n1} & a_{n2} & \ldots & a_{nn} - \lambda
\end{array} \right) \left( \begin{array}{c}
x_1\\
x_2\\
\vdots\\
x_n
\end{array} \right) &= \left( \begin{array}{c}
0\\
0\\
\vdots\\
0
\end{array} \right)
\end{align*}
$$\left\{ \begin{array}{ccl}
(a_{11}- \lambda)x_1 + a_{12} x_2 + \ldots + a_{1n} x_n & = & 0\\
a_{21}x_1 + (a_{22} - \lambda)x_2 + \ldots + a_{2n} x_n & = & 0\\
\vdots && \vdots\\
a_{n1} x_1 + a_{n2} x_2 + \ldots + (a_{nn} - \lambda) x_n & = & 0
\end{array}\right.$$

\noindent $An$, si $x = (x_1 , x_2 , \ldots , x_n)$ es un vector característico $\lambda$, se concluye que el sistema homogéneo anterior de $n$ ecuaciones tiene solución no trivial. Entonces $det (A - \lambda I) = 0$.\\
Recíprocamente, si $det(A- \lambda I)=0$, entonces el sistema homogéneo tiene soluciones no triviales y $\lambda$ es en consecuencia un valor característico.\\
Los argumentos anteriores son una prueba del siguiente teorema.
\begin{theorem}
Sea $A$ una matriz $n \times n$. Entonces $\lambda$ es un valor característico de $A$ si y solo si 
$$det(A- \lambda I) =0$$
\end{theorem}

\begin{theorem}
Sea $A$ una matriz $n \times n$ y $\lambda$ un valor característico de $A$. Entonces el conjunto $V_{\lambda} = \{v \in \rn : Av = \lambda v \} \cup  \{\mathbf{0}_{\rn}\}$ es un subespacio vectorial de \rn .
\end{theorem}

\begin{proof}
Por definición $\mathbf{0}_{\rn} \in \mathbb{V}_{\lambda}$.\\
Sean $v_1$ y $v_2$ $\in V_{\lambda}$, entonces 
\begin{align*}
A(v_1 + v_2) &= A v_1 + A v_2\\
&= \lambda v_1 + \lambda v_2\\
&= \lambda (v_1 + v_2)
\end{align*}
Por lo tanto $v_1 + v_2 \in V_{\lambda}$.
Sea $\lambda \in \mathbb{R}$ y $v \in \mathbb{V}_{\lambda}$
\begin{align*}
A(\alpha V) &= \alpha A v\\
&= \alpha \lambda V\\
&=\lambda (\alpha V)
\end{align*}
Lo cual implica que $\alpha V \in \mathbb{V}_{\lambda}$.\\
Por lo tanto $\mathbb{V}_{\lambda}$ es un subespacio vectorial de \rn .
\end{proof}

\begin{theorem}
Sea $A$ una matriz $n \times n$, \kvect{\lambda}{k} valores característicos de $A$ distintos. Entonces los vectores característicos \kvect{v}{k} relativos a los valores característícos \kvect{\lambda}{k}, son linealmente independientes.
\end{theorem}

\begin{proof}
Probemos el teorema por inducción.\\
Sea $n=2$\\
Entonces si $\lambda_1 \neq \lambda_2$ y $v_1 , v_2$ son los correspondientes vectores característicos, probaremos que son linealmente independientes.\\
Así, si $\alpha_1 v_1 + \alpha_2 v_2 = 0 \: (*)$ y multiplicamos por $A$ obtenemos 
\begin{align*}
A(\alpha_1 v_1) + A(\alpha_2 v_2) &= A \cdot 0 = 0\\
\alpha_1 A v_1 + \alpha_2 A v_2 &=0\\
\alpha_1 \lambda_1 v_1 + \alpha_2 \lambda_2 v_2 &= 0
\end{align*}
Si multiplicamos las ecuación $(*)$ por $\lambda_1$, obtenemos
$$\alpha_1 \lambda_1 v_1 + \alpha_2 \lambda_1 v_2 = 0$$
y si restamos estas dos últimas ecuaciones obtenemos $$\alpha_2 \lambda_2 v_2 - \alpha_2 \lambda_1 v_2 = 0$$
Es decir tenemos que $$\alpha_2 (\lambda_2 - \lambda_1)v_2 = 0$$
Por hipótesis $\lambda_2 -\lambda_1 \neq 0$ y $v_2 \neq \mathbf{0}$.\\
Entonces $\alpha_2 = 0$. Esto último implica que $\alpha_1 v_1 =0$ y como $v_1 \neq \mathbf{0}$ se concluye que $\alpha_1 =0$. Por lo tanto se prueba que $v_1$ y $v_2$ son linealmente independientes.\\
Supongamos ahora que para $1\leq n \leq k$ el teorema es cierto y veamos que también lo es para $n =k+1$.\\
Supongamos entonces que 
$$\beta_1 v_1 +\beta_2 v_2 + \ldots + \beta_k v_k + \beta_{k+1} v_{k+1}= 0\;(**)$$
y si multiplicamos por $A$ la ecuación $(**)$ obtenemos
$$\beta_1 A\, v_1 + \beta_2 A\, v_2 + \ldots +\beta_k A\, v_k + \beta_{k+1} A\, v_{k+1}$$
$$\beta_1 \lambda_1 v_1 + \beta_2 \lambda_2 v_2 + \ldots + \beta_k \lambda_k v_k + \beta_{k+1} \lambda_{k+1} v_{k+1}\; (***)$$
multipliquemos la ecuación $(**)$ por $\lambda_{k+1}$
$$\beta_1 \lambda_{k+1} v_1 + \beta_{2} \lambda_{k+1} v_2 + \ldots + \beta_{k} \lambda_{k+1} v_k + \beta_{k+1} \lambda_{k+1} v_{k+1} = 0$$
Si la última ecuación la restamos de $(***)$ obtenemos
$$\beta_1 (\lambda_{k+1} - \lambda_1)v_1 + \beta_2(\lambda_{k+1}- \lambda_2)v_2 + \ldots + \beta_k (\lambda{k+1} - \lambda_k)v_k + \beta{k+1}(\lambda_{k+1} - \lambda_{k+1})v_{k+1} =0$$
el cual queda como
$$\beta_1(\lambda_{k+1}-\lambda_1)v_1 + \beta_2 (\lambda_{k+1} - \lambda_2)v_2 + \ldots + \beta_k(\lambda_{k+1}-\lambda_k)v_k =0$$
Por hipótesis inductiva \conjvect{v}{R} son linealmente independientes y como $\lambda_{k+1}-\lambda_j \neq 0$ para $j = 1 \ldots k$. Obtenemos que $\beta_1 = \beta_2 = \ldots = \beta_k =0$.
La ecuación $(**)$ queda como
$$\beta_{k+1} v_{k+1} =0$$
lo cual implica que $\beta_{k+1}=0$ por cuanto $v_{k+1}\neq \mathbf{0}$
\end{proof}

\section{Multiplicidad algebraica y multiplicidad geométrica de valores característicos}
\begin{dfn}
Sea $A$ una matriz $n \times n$ y sea $p(\lambda) = det (A - \lambda I)$ si $p(\lambda) = (\lambda - \lambda_1)^{r_1} (\lambda - \lambda_2)^{r_2} \ldots (\lambda- \lambda_m)^{r_m}$. Entonces los valores $r_i : i : 1, \ldots, m$ se llaman las multiplicidades algebraicas de los valores característicos $\lambda_i : i:1, \ldots, m$.
\end{dfn}

\begin{dfn}
Sea $\lambda$ un valor característico de la matriz $A$. Entonces la multiplicidad geométrica de $\lambda$ es la dimensión del espacio $\mathbb{V}_{\lambda}$ el cual es igual a la nulidad de la transformación lineal $T(v) = (A- \lambda I)v$
\end{dfn}

\begin{theorem}
Sea $A$ una matriz $n \times n$. A tiene $n$ vectores característicos linealmente independientes si y solo si cada uno de sus valores característicos tiene multiplicidad algebraica igual a 1.
\end{theorem}

\section{Diagonalización de matrices cuadradas}
\begin{dfn}
Sean $A$ y $B$ dos matrices $n \times n$. $A$ y $B$ se dicen que son semejantes si existe una matriz invertible $P$ tal que 
$$B= P^{-1} AP$$
\end{dfn}

\begin{dfn}
Una matriz $A$ $n \times n$ es diagonalizable si es semejante a una matriz diagonal. En otra palabras si existe una matriz diagonal $D$ y una matriz invertible $P$ tal que 
$$A=P^{-1}DP$$
\end{dfn}



%%%%%%%% esta seccion son los modelos de comandos para secciones
%%ejercicio
%\begin{ejercicio}
%Sea V un espacio vectorial etc etc
%\end{ejercicio}
%
%\begin{ejemplo}
%Sea V un espacio vectorial etc etc
%\end{ejemplo}
%
%\begin{theorem}[Teorema de las dimensiones -es opcional]
%Sea V un espacio vectorial etc etc
%\end{theorem}
%
%\begin{lemma}[Nombre del lema- es opcional]
%Sea V un espacio vectorial etc etc
%\end{lemma}
%
%\begin{dfn}[Base]
%Sea V un espacio vectorial etc etc
%
%\end{dfn}

%%%%%%%%%%%%%%%%




\end{document}